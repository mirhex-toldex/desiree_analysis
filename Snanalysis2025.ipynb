{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'process_data' from '/Users/xnimir/Desktop/Sn exp 2024/process_data.py'>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import process_data\n",
    "from process_data import get_dfs\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import curve_fit  \n",
    "from scipy.special import voigt_profile\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import pickle\n",
    "import os\n",
    "import importlib\n",
    "importlib.reload(process_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(x, A, mu, sigma, B):\n",
    "    return A * np.exp(-((x - mu)**2) / (2 * sigma**2)) + B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_lorentzian(x, amplitude, center, width, offset):\n",
    "    return amplitude * width**2 / ((x - center)**2 + width**2) + offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def super_lorentzian(x, amplitude, center, width, power, offset):\n",
    "    # Generalized Lorentzian with adjustable power for wider wings\n",
    "    return amplitude * width**power / ((x - center)**power + width**power) + offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voigt(x, amplitude, center, g_width, l_width, offset):\n",
    "    basic_voigt = amplitude * voigt_profile(x - center, g_width, l_width)\n",
    "    return basic_voigt + offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modified_voigt(x, amplitude, center, g_width, l_width, offset, slope, modification_factor, transition_point):\n",
    "    penalty = 1e6 * (1 - np.exp(-g_width**2 / (1e-4))) if g_width < 1e-4 or l_width < 1e-4 else 0\n",
    "    basic_voigt = amplitude * voigt_profile(x - center, g_width, l_width)\n",
    "    wing_enhancement = modification_factor * amplitude * (g_width**2 / ((x - center)**2 + g_width**2))**0.5\n",
    "    baseline = offset + slope * np.maximum(0, x - transition_point)\n",
    "    return basic_voigt + wing_enhancement + baseline + penalty\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaus_fitting(x,y):\n",
    "    x_fit = np.linspace(np.min(x), np.max(x), 500)\n",
    "\n",
    "    initial_guess = [np.max(y), x[np.argmax(y)], np.std(x), 0]\n",
    "    bounds = ([0, 0, 0, 0], [np.inf, np.max(x), np.inf, np.inf])\n",
    "    popt, pcov = curve_fit(gaussian, x, y, p0=initial_guess, bounds=bounds, sigma=np.sqrt(y), absolute_sigma=True)\n",
    "    y_fit = gaussian(x_fit, *popt)\n",
    "\n",
    "    fwhm = 2.355 * popt[2] * 1E6\n",
    "    fit_errors_g = np.sqrt(np.diag(pcov))\n",
    "    mu_error = fit_errors_g[1]\n",
    "\n",
    "    return x_fit, y_fit, popt, pcov, fwhm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focus_on_peak(x, y, fit_width):\n",
    "    # Find the x-value of the peak (maximum y-value)\n",
    "    peak_index = np.argmax(y)\n",
    "    peak_x = x[peak_index]\n",
    "    \n",
    "    # Define the fitting window around the peak\n",
    "    x_min = peak_x - fit_width\n",
    "    x_max = peak_x + fit_width\n",
    "    \n",
    "    # Filter x and y values within the fitting window\n",
    "    mask = (x >= x_min) & (x <= x_max)\n",
    "    x_subset = x[mask]\n",
    "    y_subset = y[mask]\n",
    "    \n",
    "    return x_subset, y_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voigt_fitting(file, x, y):\n",
    "    x_fit = np.linspace(np.min(x), np.max(x), 500)\n",
    "    \n",
    "    amplitude = np.max(y)\n",
    "    center = x[np.argmax(y)]\n",
    "\n",
    "    # half_max = amplitude / 2\n",
    "    # indices_above_half_max = np.where(y >= half_max)[0]\n",
    "    # if len(indices_above_half_max) > 1:\n",
    "    #     fwhm = x[indices_above_half_max[-1]] - x[indices_above_half_max[0]]\n",
    "    #     g_width = fwhm / (2 * np.sqrt(2 * np.log(2)))  # Convert FWHM to standard deviation\n",
    "    # else:\n",
    "    #     g_width = (x[-1] - x[0]) / 10  # Fallback: estimate width as a fraction of x range\n",
    "    g_width = 200E-6 / (2 * np.sqrt(2 * np.log(2)))\n",
    "    l_width = g_width / 2  # Start with l_width smaller than g_width\n",
    "    offset = np.min(y)\n",
    "\n",
    "    weights = 1 / np.sqrt(y + 1)\n",
    "    # weights = 1 / (np.sqrt(y + 1) + np.abs(x - center) * 100)\n",
    "\n",
    "\n",
    "    # lower_bounds = [0, np.min(x), 0, 0, -np.inf, 0]  # Amplitude >= 0\n",
    "    # upper_bounds = [np.inf, np.max(x), np.max(x) - np.min(x), np.max(x) - np.min(x), np.inf, 1]  # No tight upper bounds\n",
    "\n",
    "    if any(substring in file for substring in ['Sn-114', 'Sn-122_', 'Sn-124_']):  # fixing weird shape\n",
    "        # x, y = focus_on_peak(x, y, fit_width=0.0009)\n",
    "        slope = 50000\n",
    "        modification_factor = 0.1\n",
    "        transition_point = 0.005\n",
    "        popt, pcov = curve_fit(modified_voigt, x, y, \n",
    "                        p0=[amplitude, center, g_width, l_width, offset, slope, modification_factor, transition_point])\n",
    "        y_fit = modified_voigt(x_fit, *popt)\n",
    "     \n",
    "    else:\n",
    "        popt, pcov = curve_fit(voigt, x, y, \n",
    "                            p0=[amplitude, center, g_width, l_width, offset],\n",
    "                            sigma = weights)\n",
    "                            # bounds=(lower_bounds, upper_bounds))\n",
    "        y_fit = voigt(x_fit, *popt)\n",
    "\n",
    "\n",
    "    g_width_fit = popt[2]  # Extract Gaussian width from popt\n",
    "    l_width_fit = popt[3]  # Extract Lorentzian width from popt\n",
    "    fwhm = np.sqrt(g_width_fit**2 + l_width_fit**2) * 1E6\n",
    "\n",
    "    return x_fit, y_fit, popt, pcov, fwhm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scatter_plot(data_df, time_df, freq_df, file):\n",
    "    x = data_df['Bin center']\n",
    "    y = data_df['Count raw']\n",
    "    # y_1 = gaussian_filter1d(data_df['Count raw'], sigma=2)\n",
    "    # y = data_df['Total_count']\n",
    "    # y_norm = data_df['Norm count']\n",
    "    x_fit_g, y_fit_g, popt_g, pcov_g, fwhm_g = gaus_fitting(x, y)\n",
    "    x_fit_v, y_fit_v, popt_v, pcov_v, fwhm_v = voigt_fitting(file, x, y)\n",
    "    \n",
    "\n",
    "    # plt.figure()\n",
    "    # # plt.errorbar(x, y, yerr=np.sqrt(y), fmt='o', capsize=3)\n",
    "    # plt.scatter(x,y)\n",
    "    # # plt.plot(x_fit_g, y_fit_g, color='green', label = 'G')\n",
    "    # plt.plot(x_fit_v, y_fit_v, color='red', label = 'V')\n",
    "    # plt.title(f'{file}')\n",
    "    # plt.xlabel('frequency (THz)')\n",
    "    # plt.ylabel('binned counts')\n",
    "    # # plt.legend()\n",
    "\n",
    "    # # label_g = f'Gaussian: mu={popt_g[1]:.6f} THz\\nfwhm={fwhm_g:.2f} MHz'\n",
    "    # # plt.text(0.95, 0.95, label_g, fontsize=10,\n",
    "    # #                     verticalalignment='top', horizontalalignment='right',\n",
    "    # #                     transform=plt.gca().transAxes) \n",
    "    \n",
    "    # label_v = f'mu={popt_v[1]:.6f} THz\\nfwhm={fwhm_v:.2f} MHz'\n",
    "    # plt.text(0.95, 0.95, label_v, fontsize=10,\n",
    "    #                     verticalalignment='top', horizontalalignment='right',\n",
    "    #                     transform=plt.gca().transAxes) \n",
    "    # plt.show()\n",
    "\n",
    "    # plt.title('Frequency')\n",
    "    # plt.scatter(freq_df['Bin center'], freq_df['Count raw'], color='red')\n",
    "    # plt.show()\n",
    "    # plt.title('Time')\n",
    "    # plt.scatter(time_df['Bin center'], time_df['Count raw'])\n",
    "    # plt.show()\n",
    "\n",
    "    return popt_v[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(folder_path):\n",
    "    peak_data = [] \n",
    "\n",
    "    for order, (filename, scaled_df, time_df, freq_df, isotope) in enumerate(get_dfs(folder_path), start=1):\n",
    "        peak_freq = get_scatter_plot(scaled_df, time_df, freq_df, filename)\n",
    "        peak_data.append([isotope, peak_freq, order])\n",
    "\n",
    "    return peak_data # list of tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_set():\n",
    "    folder_path = '/Users/xnimir/Desktop/Sn exp 2024/data/set1/'\n",
    "    peak_data = main(folder_path)\n",
    "    # print(peak_data)\n",
    "# single_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_sets():\n",
    "    folder_base_path = '/Users/xnimir/Desktop/Sn exp 2024/data/set'  \n",
    "    results_dict = {} \n",
    "\n",
    "    for set_number in range(1,11):  # iterated from n to n-1\n",
    "        folder_path = f'{folder_base_path}{set_number}/'  \n",
    "        peak_data = main(folder_path) # peak data = [isotope, peak, order]\n",
    "\n",
    "        # first organize by isotope \n",
    "        isotopes_dict = {}\n",
    "        for (isotope, peak, order) in peak_data: # unpack tuple \n",
    "            if isotope not in isotopes_dict:\n",
    "                isotopes_dict[isotope] = []\n",
    "            isotopes_dict[isotope].append((peak, order))  \n",
    "            \n",
    "        results_dict[set_number] = {} # looks like {1: {120: [{'peak': np.float64(195.2373446406191), 'order': 1}\n",
    "\n",
    "        for isotope, peak_order_list in isotopes_dict.items():\n",
    "            results_dict[set_number][isotope] = []  # Initialize list for each isotope\n",
    "\n",
    "            for peak, order in peak_order_list:\n",
    "                results_dict[set_number][isotope].append({\n",
    "                    'peak': peak,\n",
    "                    'order': order\n",
    "                })\n",
    "        \n",
    "    with open('results_dict.pkl', 'wb') as file:\n",
    "        pickle.dump(results_dict, file)\n",
    "\n",
    "# multiple_sets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- data looks like: {1: {120: [{'peak': np.float64(195.2373446406191), 'order': 1}\n",
    "\n",
    "an entire set can be accessed with: set_data = results_dict[set_number]\n",
    "\n",
    "accessing peak and order info for a specific isotope in a set: \n",
    "set_data = results_dict[set_number].get(isotope, [])\n",
    "for entry in set_data:\n",
    "    peak = entry['peak']\n",
    "    order = entry['order']\n",
    "\n",
    "specific isotope across all sets can be accessed with: \n",
    "isotope_data = {}\n",
    "for set_number, set_data in results_dict.items():\n",
    "    if isotope in set_data:\n",
    "        isotope_data[set_number] = set_data[isotope] -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pickled_data():\n",
    "    with open('results_dict.pkl', 'rb') as file:\n",
    "        results_dict = pickle.load(file)\n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = get_pickled_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sn_120_avgs_by_set(sn120):\n",
    "    set_numbers = list(sn120.keys())\n",
    "    avg_120_values = [sn120[set_number]['avg_120'] for set_number in set_numbers]\n",
    "    stdev_values = [sn120[set_number]['stdev'] for set_number in set_numbers]\n",
    "    peaks_120_values = [sn120[set_number]['peaks_120'] for set_number in set_numbers]\n",
    "    stdev_vals = np.array([sn120[set_number]['stdev'] for set_number in sn120.keys()])\n",
    "\n",
    "\n",
    "    plt.plot(set_numbers, avg_120_values, label='Average Peak Frequency', color='b', marker='o')\n",
    "    plt.fill_between(set_numbers, np.array(avg_120_values) - np.array(stdev_values), np.array(avg_120_values) + np.array(stdev_values), alpha=0.3, color='b', label='Â± Std Dev')\n",
    "    plt.xlabel('Set Number')\n",
    "    plt.ylabel('Average Peak Frequency')\n",
    "    plt.title('Average Sn-120 Peak Frequency by Set')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "    weights = 1 / (stdev_vals**2)\n",
    "    weighted_average = np.sum(weights * avg_120_values) / np.sum(weights)\n",
    "    combined_uncertainty = np.sqrt(1 / np.sum(weights))\n",
    "    result = f\"{weighted_average:.6f}({int(combined_uncertainty * 1e6)})\"\n",
    "    weighted_average, combined_uncertainty, result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_peaks_by_set(results, sn120):\n",
    "    for set_number, set_data in results.items():\n",
    "        # Get the isotopes and their corresponding peaks\n",
    "        isotopes = set_data['isotopes']\n",
    "        peaks = set_data['peaks']\n",
    "        peaks_120 = sn120[set_number]['peaks_120']\n",
    "        \n",
    "        # Flatten the peaks list for plotting\n",
    "        flat_peaks = [peak for sublist in peaks for peak in sublist]\n",
    "        flat_isotopes = [isotope for isotope, peak_list in zip(isotopes, peaks) for _ in peak_list]\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.scatter(flat_isotopes, flat_peaks)\n",
    "        plt.scatter([120] * len(peaks_120), peaks_120)\n",
    "\n",
    "        for isotope, peak_list in zip(isotopes, peaks):\n",
    "            for peak in peak_list:\n",
    "                plt.text(isotope, peak, f'{peak:.5f}', fontsize=8, ha='right', va='bottom')\n",
    "        \n",
    "        all_isotopes = list(set(isotopes + [120]))  # Combine isotopes and add 120\n",
    "        plt.xticks(all_isotopes, all_isotopes)\n",
    "        plt.title(f'Peak Frequencies for Set {set_number}')\n",
    "        plt.xlabel('Isotope')\n",
    "        plt.ylabel('Peak Frequency')\n",
    "        plt.show()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_by_isotope(results):\n",
    "    isotope_to_plot = 116\n",
    "\n",
    "    # Create a new figure for plotting\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    all_peaks = []\n",
    "\n",
    "    # Iterate through each set in the data and collect peaks for the chosen isotope\n",
    "    for set_number, set_data in results.items():\n",
    "        # Get the isotopes and their corresponding peaks\n",
    "        isotopes = set_data['isotopes']\n",
    "        peaks = set_data['peaks']\n",
    "        \n",
    "        # Check if the chosen isotope is in the current set\n",
    "        if isotope_to_plot in isotopes:\n",
    "            # Find the index of the chosen isotope\n",
    "            isotope_index = isotopes.index(isotope_to_plot)\n",
    "            all_peaks.extend(peaks[isotope_index])\n",
    "            \n",
    "            # Plot the peaks for this isotope in the current set\n",
    "            plt.scatter([set_number] * len(peaks[isotope_index]), peaks[isotope_index], label=f'Set {set_number}')\n",
    "\n",
    "    # Set plot labels and title\n",
    "    plt.title(f'Peak Frequencies for Isotope {isotope_to_plot} Across All Sets')\n",
    "    plt.xlabel('Set Number')\n",
    "    plt.ylabel('Peak Frequency')\n",
    "    plt.show()\n",
    "\n",
    "    average_peak = np.mean(all_peaks)\n",
    "    stddev_peak = np.std(all_peaks)\n",
    "\n",
    "    # Format the output as mean(stddev) with 5 decimal places for mean and 2 for stddev\n",
    "    formatted_result = f\"{average_peak:.6f}({int(stddev_peak * 1e6):02d})\"\n",
    "    print(f\"Average peak frequency for isotope {isotope_to_plot}: {formatted_result}\")\n",
    "    print(average_peak,stddev_peak)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
